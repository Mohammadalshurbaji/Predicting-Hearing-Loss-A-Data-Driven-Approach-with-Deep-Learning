{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4151dd19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of              ID  PT500  PT4000\n",
      "0    smwp1_0001   25.0    72.5\n",
      "1    smwp1_0002    5.0    10.0\n",
      "2    smwp1_0003    5.0    45.0\n",
      "3    smwp1_0004    5.0    15.0\n",
      "4    smwp1_0005    2.5    62.5\n",
      "..          ...    ...     ...\n",
      "166  smwp1_0167    0.0    27.5\n",
      "167  smwp1_0168   37.5     2.5\n",
      "168  smwp1_0169    7.5    10.0\n",
      "169  smwp1_0170    0.0    -2.5\n",
      "170  smwp1_0171   10.0    57.5\n",
      "\n",
      "[171 rows x 3 columns]>\n",
      "<bound method DataFrame.info of              ID  PT500  PT4000\n",
      "0    smwp1_0001   25.0    72.5\n",
      "1    smwp1_0002    5.0    10.0\n",
      "2    smwp1_0003    5.0    45.0\n",
      "3    smwp1_0004    5.0    15.0\n",
      "4    smwp1_0005    2.5    62.5\n",
      "..          ...    ...     ...\n",
      "165  smwp1_0166    2.5     2.5\n",
      "166  smwp1_0167    0.0    27.5\n",
      "167  smwp1_0168   37.5     2.5\n",
      "168  smwp1_0169    7.5    10.0\n",
      "170  smwp1_0171   10.0    57.5\n",
      "\n",
      "[162 rows x 3 columns]>\n",
      "{104, 169, 51, 19, 85, 118, 23, 57, 26}\n",
      "Max Before Normalization: 1.1022199392318726\n",
      "Max After Normalization: 1.0\n",
      "Completed run one\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import os\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#This block for playing with Excel Data\n",
    "df = pd.read_excel(\"PTs_500_4k_blinded.xlsx\")\n",
    "df.head()\n",
    "print(df.info)\n",
    "\n",
    "del_indices = set() #To keep in track with the deleted values\n",
    "# Filter out rows with negative values\n",
    "#This is means that we do have (171-163+1 negative values)\n",
    "negative_values_filter = (df.iloc[:, 1] < 0) | (df.iloc[:, 2] < 0)\n",
    "df_filtered = df[~negative_values_filter]\n",
    "del_indices.update(df[negative_values_filter].index)\n",
    "\n",
    "#getting red of the outliers\n",
    "#This is means that we do have 1 outlier\n",
    "Z_scores = stats.zscore(df_filtered.iloc[:,1])\n",
    "threshold = 3\n",
    "outliers_filter = Z_scores >= threshold\n",
    "df_without_outliers = df_filtered[~outliers_filter]\n",
    "del_indices.update(df_filtered[outliers_filter].index)\n",
    "print(df_without_outliers.info)\n",
    "\n",
    "#Our final preprocessed data is df_without_outliers\n",
    "# To keep track of the deleted indices, to delete the associated photos as well\n",
    "print(del_indices)\n",
    "\n",
    "dir = r'/Users/mathewbernard/downloads/8650dataset'\n",
    "\n",
    "nii_data = []\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith('.nii'):\n",
    "        filepath = os.path.join(dir, file)\n",
    "        img = nib.load(filepath)\n",
    "        data = img.get_fdata()\n",
    "        nii_data.append(data)\n",
    "        #plt.imshow(data[:, :, data.shape[2] // 2], cmap='gray')  # Display a slice from the middle of the image\n",
    "        #plt.title(f'Sample MRI Image - {file}')\n",
    "        #plt.colorbar()\n",
    "        #plt.show()\n",
    "        \n",
    "#print(len(nii_data))\n",
    "nii_data_array = np.array(nii_data)\n",
    "\n",
    "#Normalize the image data to be between Zero and 1\n",
    "#before normalization\n",
    "print(f'Max Before Normalization: {nii_data_array.max()}')\n",
    "#After Normalization\n",
    "nii_data_reshaped = nii_data_array.reshape(-1,nii_data_array.shape[-1])\n",
    "scaler = MinMaxScaler()\n",
    "nii_data_normalized = scaler.fit_transform(nii_data_reshaped)\n",
    "nii_data_normalized = nii_data_normalized.reshape(nii_data_array.shape)\n",
    "print(f'Max After Normalization: {nii_data_normalized.max()}')\n",
    "\n",
    "X = nii_data_normalized # Image Data\n",
    "y = df_without_outliers[['PT500','PT4000']].values #Threeshold Data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state=42)\n",
    "X_train, X_eval, y_train,y_eval = train_test_split(X,y,test_size=0.1,random_state=42)\n",
    "\n",
    "print(\"Completed run one\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3f77fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build model\n",
      "57728649\n",
      "66\n",
      "running compilation of model\n",
      "training model\n",
      "Epoch 1/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 762.0740 - mae: 20.9046 - val_loss: 789.9417 - val_mae: 17.9922\n",
      "Epoch 2/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 626.3597 - mae: 17.1944 - val_loss: 705.9169 - val_mae: 17.1599\n",
      "Epoch 3/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 560.8741 - mae: 16.3753 - val_loss: 667.5400 - val_mae: 16.8673\n",
      "Epoch 4/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 536.2114 - mae: 15.7132 - val_loss: 641.1530 - val_mae: 16.6525\n",
      "Epoch 5/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - loss: 472.5447 - mae: 14.6368 - val_loss: 618.2202 - val_mae: 16.5357\n",
      "Epoch 6/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 452.2332 - mae: 14.4397 - val_loss: 600.0858 - val_mae: 16.4529\n",
      "Epoch 7/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 453.2070 - mae: 14.4849 - val_loss: 583.8818 - val_mae: 16.3722\n",
      "Epoch 8/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 479.8616 - mae: 15.0573 - val_loss: 570.4839 - val_mae: 16.3235\n",
      "Epoch 9/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 467.0729 - mae: 15.0900 - val_loss: 559.0826 - val_mae: 16.3236\n",
      "Epoch 10/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 403.4723 - mae: 14.0129 - val_loss: 548.3528 - val_mae: 16.3236\n",
      "Epoch 11/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 445.4369 - mae: 14.8260 - val_loss: 538.9283 - val_mae: 16.3236\n",
      "Epoch 12/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 447.2663 - mae: 14.5882 - val_loss: 531.4573 - val_mae: 16.3236\n",
      "Epoch 13/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 361.8132 - mae: 13.3973 - val_loss: 523.9824 - val_mae: 16.3249\n",
      "Epoch 14/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 442.0763 - mae: 14.6177 - val_loss: 515.2165 - val_mae: 16.4452\n",
      "Epoch 15/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 343.7453 - mae: 13.0662 - val_loss: 507.3313 - val_mae: 16.5607\n",
      "Epoch 16/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 357.9414 - mae: 13.9212 - val_loss: 499.8204 - val_mae: 16.6776\n",
      "Epoch 17/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 385.1623 - mae: 14.0968 - val_loss: 494.5926 - val_mae: 16.7641\n",
      "Epoch 18/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - loss: 344.9286 - mae: 13.7519 - val_loss: 489.2668 - val_mae: 16.8570\n",
      "Epoch 19/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 440.0643 - mae: 15.1264 - val_loss: 484.5477 - val_mae: 16.9444\n",
      "Epoch 20/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 386.5659 - mae: 13.9004 - val_loss: 479.9338 - val_mae: 17.0353\n",
      "Epoch 21/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 375.3217 - mae: 14.4486 - val_loss: 475.2064 - val_mae: 17.1352\n",
      "Epoch 22/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 373.1202 - mae: 14.6078 - val_loss: 471.7455 - val_mae: 17.2138\n",
      "Epoch 23/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - loss: 349.3383 - mae: 13.5506 - val_loss: 468.7894 - val_mae: 17.2852\n",
      "Epoch 24/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - loss: 337.5994 - mae: 13.7574 - val_loss: 466.0355 - val_mae: 17.3560\n",
      "Epoch 25/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 407.5799 - mae: 15.1679 - val_loss: 464.5618 - val_mae: 17.3960\n",
      "Shape of X_test_reshaped: (33, 113, 15481)\n",
      "Shape of y_test: (33, 2)\n",
      "evaluating model\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 352.1443 - mae: 16.3766 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 352.1443 - mae: 16.3766 \n",
      "Test Loss: [291.0108642578125, 16.285104751586914]\n",
      "Test MAE: [291.0108642578125, 16.285104751586914]\n",
      "completed model build and evaluation\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "print(\"running build model\")\n",
    "\n",
    "# Reshape data\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], -1)\n",
    "X_val_reshaped = X_eval.reshape(X_eval.shape[0], X_eval.shape[1], -1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], -1)\n",
    "\n",
    "print(X_test_reshaped.size)\n",
    "print(y_test.size)\n",
    "\n",
    "#model definiton - regularizers apply L2\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=64, return_sequences=True, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.SimpleRNN(units=64, return_sequences=True, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.SimpleRNN(units=64, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(units=1, kernel_regularizer=regularizers.l2(0.01))\n",
    "])\n",
    "\n",
    "# Compile\n",
    "print(\"running compilation of model\")\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Training\n",
    "print(\"training model\")\n",
    "history = model.fit(X_train_reshaped, y_train,\n",
    "                    validation_data=(X_val_reshaped, y_eval),\n",
    "                    batch_size=16,\n",
    "                    epochs=25)\n",
    "\n",
    "print(\"Shape of X_test_reshaped:\", X_test_reshaped.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"evaluating model\")\n",
    "loss = model.evaluate(X_test_reshaped, y_test_subset)\n",
    "mae = model.evaluate(X_test_reshaped, y_test_subset)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MAE:\", mae)\n",
    "\n",
    "print(\"completed model build and evaluation\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1764e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
